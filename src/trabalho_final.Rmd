---
title: "Projeto_final_Bates_Granger"
output: html_notebook
---

```{r}
library(readxl)
library(here)
library(dplyr)
library(data.table)
library(xtable)
library(vars)
library(forecast)
library(GeomComb)
library(tidyr)
library(MLmetrics)
```

### Base de dados

Um dos indicadores mais importantes dos estados unidos é o "Institute of Supply Management (ISM) Manufacturing Purchasing Managers Index (PMI)", mais conhecido no mercado como ISM. Este relatorio é baseado em dados copilados de respotas mensais a executivos do lado da demanda e da oferta em mais de 400 companias.

Um fato importante para os agentes que tentam antecipar o ISM é que muitos estados reportam antecipadamente seus ISM. Portanto, é comum utilizar os ISMs estaduais como variáveis independentes no modelo.

### Objetivo

O objetivo principal deste projeto será implementar a metodologia de combinação de previsão proposta por Bates e Granger (1989) utilizando uma série de metodos de previsão no contexto de séries temporais. Mais especificamente, testarermos os seguintes modelos:

> **(1)** ARIMA

> **(2)** ARIMAX

> **(3)** Regressão linear com erros gaussianos

> **(4)** VAR

Uma vez em posse das estimações dentro da amostra destes modelos, utilizaremos o procedimento de previsão recursiva para avaliar, utiliando a metrica "mean squared erro (MSE)", os erros de previsão de cada um dos modelos individualmente, de uma combinação por média, e da combinação proposta por Bates e Granger.

```{r}
df = readxl::read_excel(here::here('src', 'data', 'ISM.xlsx'))
df = df[, c('date', 'ISM_Head', 'TX_ISM', 'KAN_ISM', 'EMP_ISM', 'PHI_ISM', 'RICH_ISM')]
df = df[complete.cases(df), ]

df_est = df[1:100,] %>% dplyr::select(-date)
df_fore = df[101:dim(df)[1],] %>% dplyr::select(-date)

head(df)

```
### ARIMA(p, j, q)

Como visto em aula, utilizaremos os criterios de informacao para determinar os termos $p$ e $q$.

A combinação que minimiza o criterio BIC é ar(10) e ma(2), portanto este será nossa especificação do modelo ARMA

```{r}
ism_arma = list('AIC' = data.table(), 'BIC' = data.table())
for (ar.lag in 0:10) {
  arma.stat = rep(0, 6)
  for (ma.lag in 0:2) {
    arma.fit = arima(df_est[,c('ISM_Head')], order = c(ar.lag, 0, ma.lag))
    # arma.fit
    # AIC
    arma.stat[ma.lag + 1] <- arma.fit$aic
    # BIC
    arma.stat[ma.lag + 4] <- -2 * arma.fit$loglik + (ar.lag + ma.lag) * log(length(df_est[,c('ISM_Head')]))
  }
  ism_arma$AIC = rbindlist(list(ism_arma$AIC, data.table(t(arma.stat[1:3]))))
  ism_arma$BIC = rbindlist(list(ism_arma$BIC, data.table(t(arma.stat[4:6]))))
}
setnames(ism_arma$AIC, c('MA0', 'MA1', 'MA2'))
ism_arma$AIC[, AR := 0:10]
setnames(ism_arma$BIC, c('MA0', 'MA1', 'MA2'))
ism_arma$BIC[, AR := (0:10)]


BIC_selec.mat = rbind(ism_arma$BIC[, AR := (0:10)])
print(xtable(BIC_selec.mat))

```
### ARIMAX(p, j, q)

O modelo arimax é simplesmente o modelo modelo arima com variáveis exogenas. Utilizaremos uma especificação mais simples do que a encontrada anteriormente mas colocaremos todas os outros ISM como variaveis exógenas.

### O modelo de regressão linear com erros gaussianos

Mais simples de todos. Utilizaremos o modelos de regressão tradicional com erros gaussianos e constante, além de usar todos os outros ISM como variáveis exógenas.

### VAR

Utilizaremos o mesmo procedimento de especificação da ordem $p$ do VAR(p) utilizado no modelo ARMA para determinar quantos termos autoregressivos utilizaremos na regressão.

De acordo com todos os critérios, inclusive o AIC, o número de termos autoregressivos $p$ que os minimiza é 1. 

```{r}
VARselect(df_est, lag.max = 5)

```

### Função de previsão fora da amostra

```{r}
pred_list = list()
pred_list1 = list()
realized = list()
df_oos = df %>% drop_na() %>% dplyr::select(-date)
j = 1

# MODEL ESTIMATION FOR THE FORECAST COMB
modd_arima = Arima(y = df_oos[1:100, c('ISM_Head')], order = c(10, 0, 2))
modd_arimax = Arima(y = df_oos[1:100, c('ISM_Head')], xreg = as.matrix(df_oos[1:100, c('TX_ISM', 'KAN_ISM', 'EMP_ISM', 'PHI_ISM', 'RICH_ISM')]),
                       order = c(1, 0, 1))
modd_lm = lm(ISM_Head ~TX_ISM + KAN_ISM + EMP_ISM + PHI_ISM + RICH_ISM,  df_oos[1:100, ])
modd_var = VAR(df_oos[1:100, c('ISM_Head', 'TX_ISM', 'KAN_ISM', 'EMP_ISM', 'PHI_ISM', 'RICH_ISM')], p=1)
modd_var_fitted = fitted(modd_var) %>% as.data.frame() %>% dplyr::select(ISM_Head)
colnames(modd_var_fitted) = c('var')

df_fitted = list(arima=as.matrix(modd_arima$fitted)[2:100], arimax=as.matrix(modd_arimax$fitted)[2:100],
                 lm=as.matrix(modd_lm$fitted.values)[2:100], var=as.matrix(modd_var_fitted)) %>% as.data.frame() %>% mutate(mean=rowMeans(df_fitted))


for (i in 100:(dim(df_oos)[1]-1)){
    comb = list()
    
    # ARIMA
    modd_arima = Arima(y = df_oos[1:i, c('ISM_Head')], order = c(10, 0, 2))
    pred_arima = predict(modd_arima, n.ahead = 1)
    pred_list[['arima']][j] = pred_arima$pred[1]
    comb[1] = pred_arima$pred[1]
    
    
    # ARIMAX
    modd_arimax = Arima(y = df_oos[1:i, c('ISM_Head')], xreg = as.matrix(df_oos[1:i, c('TX_ISM', 'KAN_ISM', 'EMP_ISM', 'PHI_ISM', 'RICH_ISM')]),
                       order = c(1, 0, 1))
    pred_arimax = predict(modd_arimax, newxreg = as.matrix(df_oos[i+1, c('TX_ISM', 'KAN_ISM', 'EMP_ISM', 'PHI_ISM', 'RICH_ISM')]),
                         n.ahead = 1)
    pred_list[['arimax']][j] = pred_arimax$pred[1]
    comb[2] = pred_arimax$pred[1]

    
    # LINEAR GAUSSIAN MODEL
    modd_lm = lm(ISM_Head ~TX_ISM + KAN_ISM + EMP_ISM + PHI_ISM + RICH_ISM,  df_oos[1:i, ])
    pred_lm = predict(modd_lm, newxreg = df_oos[i+1, c('TX_ISM', 'KAN_ISM', 'EMP_ISM', 'PHI_ISM', 'RICH_ISM')],
                     n.ahead = 1)
    pred_list[['lm']][j] = pred_lm[[1]]
    comb[3] = pred_lm[[1]]

    
    # VAR MODEL
    modd_var = VAR(df_oos[1:i, c('ISM_Head', 'TX_ISM', 'KAN_ISM', 'EMP_ISM', 'PHI_ISM', 'RICH_ISM')], p=1)
    pred_var = predict(modd_var, n.ahead = 1)
    pred_list[['var']][j] = pred_var$fcst$ISM_Head[1]
    comb[4] = pred_var$fcst$ISM_Head[1]
    

    # MEAN FORECAST
    pred_mean = mean(do.call('rbind', comb), na.rm=TRUE)
    pred_list[['mean']][j] = pred_mean
    
    realized[j] = df_oos[i+1, c('ISM_Head')][[1]]

    # BATES GRNAGER COMBINATION
    fcomb = foreccomb(observed_vector = as.matrix(as.matrix(df_oos[1:i+1, c('ISM_Head')])),
                      prediction_matrix = as.matrix(rbind(df_fitted, do.call('cbind', pred_list))))
    pred_bg = comb_BG(fcomb)
    pred_list1[['bg']][j] = (t(data.matrix(pred_bg$Weights)) %*% as.matrix(as.numeric(comb)))[1]
    
    
    j = j+1
}

```

```{r}
realized = as.matrix(realized) %>% as.data.frame() %>% mutate(ISM=V1) %>% dplyr::select(-V1)
df_bg = as.data.frame(pred_list1$bg)
colnames(df_bg) = c('bg')
df_final = do.call('cbind', pred_list) %>% as.data.frame() %>% mutate(bg=df_bg$bg)

df_all = cbind(realized, df_final) %>% as.data.frame()
```

### MSE

```{r}
target = 'ISM'
mse_list = list()
for (name in colnames(df_all)){
  if (name == target){
    next
  }else{
    mse = MSE(y_pred = as.matrix(as.numeric(df_all[[name]])), y_true = as.matrix(as.numeric(df_all[[target]])))
    mse_list[[name]] = mse
  }
}
as.data.frame(mse_list)
```

```{r}

```

```{r}

```



